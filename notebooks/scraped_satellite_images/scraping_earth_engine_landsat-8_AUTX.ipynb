{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes satellite images for each leak repair. For each location it gets a NxM rectangle around the leak before and after it was repaired. Then it collated all the data into h5 files and all the metadata into json files.\n",
    "\n",
    "It takes days to run because of rate limiting on the google earth api. Because of limited satelite coverage you might find matches for only 10% of the leaks.\n",
    "\n",
    "## Modifying\n",
    "\n",
    "- make sure google earth is setup\n",
    "- load leaks, so they pass the asserts\n",
    "- change params\n",
    "- run rest of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T01:23:25.924228Z",
     "start_time": "2017-03-21T09:23:23.576578+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.4f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from path import Path\n",
    "import arrow\n",
    "import json\n",
    "import pytz\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re, os, collections, itertools, uuid, logging\n",
    "import tempfile\n",
    "import tables\n",
    "\n",
    "import zipfile\n",
    "import urllib\n",
    "\n",
    "import ee\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5) # bigger plots\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "%precision 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T01:23:25.949690Z",
     "start_time": "2017-03-21T09:23:25.942795+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T01:23:29.641037Z",
     "start_time": "2017-03-21T09:23:25.968769+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper_dir = str(Path('..').abspath())\n",
    "if helper_dir not in os.sys.path:\n",
    "    os.sys.path.append(helper_dir)\n",
    "    \n",
    "from leak_helpers.earth_engine import display_ee, get_boundary, tifs2np, bands_s2, download_image, bands_s2, bands_s1, bands_l7, bands_l8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:12:16.420092Z",
     "start_time": "2017-03-21T10:12:16.407508+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/tmp/testing_earth_engine-l8-AUTX_v2-82dzkbkv-20170321-02-12-16'),\n",
       " Path('../data/20170314-05-26-52_testing_earth_engine-l8-AUTX_v2'),\n",
       " Path('../data/20170314-05-26-52_testing_earth_engine-l8-AUTX_v2/ee_l8_AUTX-leaks_cache_v2/ATX_'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crs_grid = 3857\n",
    "notebook_name='testing_earth_engine-l8-AUTX_v2'\n",
    "\n",
    "satellite = 'LANDSAT/LC8_L1T'\n",
    "bands = bands_l8\n",
    "\n",
    "# since the lowest res band is 60m and I want to capture neighbours I should get 6+ pixels\n",
    "pixel_length = 25.0\n",
    "resolution_min = 15.0 # m\n",
    "time_bin_delta = 60*60*24*28 # how long before a leak to look (in seconds)\n",
    "# TODO get closest but let me filter for time\n",
    "\n",
    "# init\n",
    "ts=arrow.utcnow().format('YYYYMMDD-HH-mm-ss')\n",
    "data_dir = Path('../../data/')\n",
    "temp_dir = Path(tempfile.mkdtemp(prefix=notebook_name+'-', suffix='-'+ts))\n",
    "output_dir = Path('../../data/scraped_satellite_images/20170314-05-26-52_testing_earth_engine-l8-AUTX_v2')\n",
    "cache_dir = output_dir.joinpath('ee_l8_AUTX-leaks_cache_v2/ATX_')\n",
    "\n",
    "output_dir.makedirs_p()\n",
    "temp_dir.makedirs_p()\n",
    "cache_dir.makedirs_p()\n",
    "\n",
    "logger = logging.getLogger(notebook_name)\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "crs_grid_proj = pyproj.Proj('+init=epsg:%s'%crs_grid)\n",
    "\n",
    "temp_dir, output_dir, cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:12:18.811768Z",
     "start_time": "2017-03-21T10:12:18.806156+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# write metadata to json\n",
    "metadata = dict(\n",
    "    satellite=satellite,\n",
    "    notebook_name=notebook_name,\n",
    "    time_bin_delta=time_bin_delta,\n",
    "    pixel_length=pixel_length,\n",
    "    resolution_min=resolution_min,\n",
    "    bands=bands,\n",
    "    ts=ts,\n",
    "    crs_grid=crs_grid,\n",
    "    cache_dir=str(cache_dir),\n",
    "    temp_dir=str(temp_dir),\n",
    "    output_dir=str(output_dir),\n",
    ")\n",
    "metadata_file = output_dir.joinpath('script_metadata.json')\n",
    "json.dump(metadata, open(metadata_file,'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# earth engine\n",
    "\n",
    "Setup instructions here\n",
    "- first need to apply for an account and wait ~ 1day\n",
    "- https://developers.google.com/earth-engine/python_install#setting-up-authentication-credentials\n",
    "\n",
    "Refs:\n",
    "- api https://developers.google.com/earth-engine/\n",
    "- code examples https://code.earthengine.google.com/\n",
    "- sentinel1 https://developers.google.com/earth-engine/sentinel1\n",
    "    - `ee.ImageCollection('COPERNICUS/S2_GRD');`\n",
    "    - `ee.ImageCollection('COPERNICUS/S1_GRD');`\n",
    "- keras and google earth https://github.com/patrick-dd/landsat-landstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:12:23.143469Z",
     "start_time": "2017-03-21T10:12:20.589769+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# test earth-engine setup\n",
    "from oauth2client import crypt # should have not error\n",
    "import ee\n",
    "ee.Initialize() # should give no errors, if so follow instructions\n",
    "\n",
    "\n",
    "# test\n",
    "image = ee.Image('srtm90_v4')\n",
    "assert image.getInfo()=={'type': 'Image', 'properties': {'system:time_start': 950227200000, 'system:asset_size': 18827626666, 'system:time_end': 951177600000}, 'bands': [{'data_type': {'type': 'PixelType', 'max': 32767, 'min': -32768, 'precision': 'int'}, 'crs': 'EPSG:4326', 'id': 'elevation', 'dimensions': [432000, 144000], 'crs_transform': [0.000833333333333, 0.0, -180.0, 0.0, -0.000833333333333, 60.0]}], 'id': 'srtm90_v4', 'version': 1463778555689000}\n",
    "print('ok')\n",
    "\n",
    "# ee.Geometry.Point([117.21079620254062, -30.94712385398404])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:12:25.813946Z",
     "start_time": "2017-03-21T10:12:23.145048+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7910"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load wa leaks\n",
    "leaks = gpd.read_file(data_dir.joinpath('leak_datasets/austin_leaks/derived/austin_leaks-repairs.geojson'))\n",
    "\n",
    "\n",
    "# they have to be after launch\n",
    "s3_launch_ts=pd.Timestamp('Apr 11, 2013')\n",
    "leaks = leaks[pd.to_datetime(leaks.COMPDTTM)>=s3_launch_ts]\n",
    "\n",
    "leaks.index = leaks.leak_id\n",
    "len(leaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T05:46:36.432522Z",
     "start_time": "2017-03-14T13:46:36.410901+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:12:25.844139Z",
     "start_time": "2017-03-21T10:12:25.815680+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>22</th>\n",
       "      <th>ADDRKEY</th>\n",
       "      <th>CITY</th>\n",
       "      <th>COMPDTTM</th>\n",
       "      <th>DESCRIPT</th>\n",
       "      <th>FullStreetName</th>\n",
       "      <th>INITDTTM</th>\n",
       "      <th>LOC</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>PREDIR</th>\n",
       "      <th>...</th>\n",
       "      <th>REPO_Date</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>STNO</th>\n",
       "      <th>STSUB</th>\n",
       "      <th>SUFFIX</th>\n",
       "      <th>WONO</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>geometry</th>\n",
       "      <th>id</th>\n",
       "      <th>leak_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leak_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ATX-66276</th>\n",
       "      <td>980381.0</td>\n",
       "      <td>624836.0</td>\n",
       "      <td>AUSTIN</td>\n",
       "      <td>2014-12-23T05:36:00</td>\n",
       "      <td>WATER MAIN LEAK</td>\n",
       "      <td>501 CONGRESS AVE</td>\n",
       "      <td>2014-11-19T20:09:00</td>\n",
       "      <td>IN ALLEYWAY BY BRAZOS</td>\n",
       "      <td>66276</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2014-12-23T05:36:00</td>\n",
       "      <td>CONGRESS</td>\n",
       "      <td>501</td>\n",
       "      <td></td>\n",
       "      <td>AVE</td>\n",
       "      <td>1546404.0</td>\n",
       "      <td>78701-</td>\n",
       "      <td>POINT (-97.7426138688088 30.26731104576194)</td>\n",
       "      <td>66276</td>\n",
       "      <td>ATX-66276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 22   ADDRKEY    CITY             COMPDTTM         DESCRIPT  \\\n",
       "leak_id                                                                       \n",
       "ATX-66276  980381.0  624836.0  AUSTIN  2014-12-23T05:36:00  WATER MAIN LEAK   \n",
       "\n",
       "             FullStreetName             INITDTTM                    LOC  \\\n",
       "leak_id                                                                   \n",
       "ATX-66276  501 CONGRESS AVE  2014-11-19T20:09:00  IN ALLEYWAY BY BRAZOS   \n",
       "\n",
       "           OBJECTID PREDIR    ...                REPO_Date    STNAME STNO  \\\n",
       "leak_id                       ...                                           \n",
       "ATX-66276     66276           ...      2014-12-23T05:36:00  CONGRESS  501   \n",
       "\n",
       "           STSUB SUFFIX       WONO         ZIP  \\\n",
       "leak_id                                          \n",
       "ATX-66276           AVE  1546404.0  78701-       \n",
       "\n",
       "                                              geometry     id    leak_id  \n",
       "leak_id                                                                   \n",
       "ATX-66276  POINT (-97.7426138688088 30.26731104576194)  66276  ATX-66276  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose one leak for now\n",
    "leak = leaks.sample()\n",
    "leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:12:25.946950Z",
     "start_time": "2017-03-21T10:12:25.845774+08:00"
    }
   },
   "outputs": [],
   "source": [
    "leaks['REPO_Date']=leaks['COMPDTTM']\n",
    "leaks['leak_id']=leaks.id.apply(lambda x:'ATX_%s'%x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-15T10:46:31.548298",
     "start_time": "2017-01-15T10:46:31.546367"
    }
   },
   "source": [
    "# Fetching sentinal-1 and sentinel 2 images\n",
    "\n",
    "For a leak repair, grab the image before and after it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note roughly 10% have results for a 1 day temporal bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:14:28.659421Z",
     "start_time": "2017-03-21T10:14:28.649025+08:00"
    }
   },
   "outputs": [],
   "source": [
    "def get_cached_ids():\n",
    "    cache_dirs = []\n",
    "    for f in cache_dir.listdir():\n",
    "        f=f.relpath(cache_dir)\n",
    "        f=Path(f.replace('ATX-','').replace('ATX_',''))\n",
    "        n=str(f).split('_')[0]\n",
    "        cache_dirs.append(n)\n",
    "    return cache_dirs\n",
    "\n",
    "def init_cache(leak_id):\n",
    "    \"\"\"We will cache downloads in folders like 'id_after'\"\"\"\n",
    "    if leak_id:\n",
    "        cache_subdir = cache_dir.joinpath(leak_id+'_after')\n",
    "        cache_subdir.makedirs_p()\n",
    "        cache_subdir = cache_dir.joinpath(leak_id+'_before')\n",
    "        cache_subdir.makedirs_p()\n",
    "    return get_cached_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:13:50.786589Z",
     "start_time": "2017-03-21T10:13:50.531543+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:14:15.413809Z",
     "start_time": "2017-03-21T10:14:14.131901+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each point\n",
    "- find the nearest image before the repair\n",
    "- and the soonest image after repair\n",
    "- save a part of each with metadata\n",
    "\n",
    "Later we can filter, interpolate, and read into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T01:03:46.200496Z",
     "start_time": "2017-03-15T09:03:46.184042+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T01:23:45.582977Z",
     "start_time": "2017-03-21T09:23:45.575379+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance = resolution_min*(pixel_length/2.0-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T09:09:56.549698Z",
     "start_time": "2017-03-15T17:09:56.538419+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-18T02:21:54.608682Z",
     "start_time": "2017-03-18T10:21:43.136913+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2040 [((25, 25), 7535399.0), ((25, 25), 14426899.0), ((25, 25), 6713718.0), ((25, 25), 6654434.0), ((25, 25), 8400010.0), ((25, 25), 0.0), ((25, 25), 0.0), ((25, 25), 6832393.0), ((25, 25), 6751405.0)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0b9c6193a8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrs_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtifs2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbands_l7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/isisilon/Data/My_Documents/Documents/eclipse-workspace/leak_detection/notebooks/leak_helpers/earth_engine.py\u001b[0m in \u001b[0;36mdownload_image\u001b[0;34m(clipped_image, scale, crs, name, cache_dir, progress_bar, report)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 path, zip_dwn_file, reporthook=my_hook(t))\n\u001b[1;32m    154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mzip_dwn_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_dwn_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mzip_dwn_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 473\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1217\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_content_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iso-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmessage_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0mmessage_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;31m# message_body was not a string (i.e. it is a file), and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0;32m-> 1230\u001b[0;31m                                                   server_hostname=sni_hostname)\n\u001b[0m\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    362\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                          _context=self)\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_npn_protocols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpn_protocols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context)\u001b[0m\n\u001b[1;32m    575\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test with one image\n",
    "for i in (np.random.sample(5)*len(leaks)).astype(np.int):\n",
    "    leak=leaks.iloc[[i]]\n",
    "    leak_id = str(leak.leak_id.values[0])\n",
    "\n",
    "    repo_date_ts = arrow.get(leak.REPO_Date.values[0]).timestamp\n",
    "    boundary = get_boundary(leak, distance=distance)\n",
    "    sentinel2_before = ee.ImageCollection(satellite)\\\n",
    "        .filterBounds(boundary)\\\n",
    "        .filterDate(933828614605,1488776737937)\\\n",
    "        .sort('system:time_start', opt_ascending=False) # first will be latest\n",
    "    image = ee.Image(sentinel2_before.first()).clip(boundary)\n",
    "    image.getInfo()\n",
    "    name=leak_id+'_after'\n",
    "    path,files=download_image(\n",
    "        image, \n",
    "        scale=resolution_min, \n",
    "        crs=crs_grid, \n",
    "        name=name,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "    data = tifs2np(path,files,bands=bands_l7)\n",
    "    print(i, [(d.shape,d.sum()) for d in data])\n",
    "    for d in data:\n",
    "        assert d.shape[0]==pixel_length, 'the downloaded image is the wrong size, tweak distance'\n",
    "        assert d.shape[1]==pixel_length\n",
    "    assert np.sum(data)!=0,'should not be empty (make sure you are using the right bands)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-18T02:21:59.369616Z",
     "start_time": "2017-03-18T10:21:59.367598+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# np.argwhere(leaks.leak_id==57914)\n",
    "# leaks.leak_id.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T05:01:16.436007Z",
     "start_time": "2017-03-21T10:46:27.555955+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4780071b9d488aafd653c766694833"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time, traceback\n",
    "cached_ids = get_cached_ids()\n",
    "\n",
    "def get_image_for_leak(i, cached_ids=cached_ids):    \n",
    "    leak = leaks.loc[[i]]\n",
    "    repo_date_ts = arrow.get(leak.REPO_Date.values[0]).timestamp\n",
    "    \n",
    "    # crappy way or recording that we tried this one\n",
    "    leak_id = str(leak.leak_id.values[0])\n",
    "    if leak_id in cached_ids:\n",
    "        logger.info('Skipping cached download for leak id %s ',leak_id)\n",
    "        return\n",
    "    \n",
    "    boundary = get_boundary(leak, distance=distance)\n",
    "    \n",
    "    # get image day before    \n",
    "    sentinel2_before = ee.ImageCollection(satellite)\\\n",
    "        .filterBounds(boundary)\\\n",
    "        .filterDate((repo_date_ts-time_bin_delta)*1000,(repo_date_ts)*1000)\\\n",
    "        .sort('system:time_start', opt_ascending=False) # first will be latest\n",
    "    \n",
    "    results = sentinel2_before.size().getInfo()\n",
    "    if results<1:\n",
    "        logger.info('Error no results for day before %s',leak_id)\n",
    "        cached_ids = init_cache(leak_id) # so we know there where no results\n",
    "        return\n",
    "        \n",
    "    # get image day after\n",
    "    sentinel2_after = ee.ImageCollection(satellite)\\\n",
    "        .filterBounds(boundary)\\\n",
    "        .filterDate((repo_date_ts)*1000,(repo_date_ts+time_bin_delta*6)*1000)\\\n",
    "        .sort('system:time_start', opt_ascending=True) # first will be earliest\n",
    "        \n",
    "    results = sentinel2_after.size().getInfo()\n",
    "    if results<1:\n",
    "        logger.info('Error no results for day after, id %s',leak_id)\n",
    "        cached_ids = init_cache(leak_id) # so we know there where no results\n",
    "        return\n",
    "        \n",
    "    # download as save images    \n",
    "    logger.info('results for %s', leak_id)\n",
    "    image = ee.Image(sentinel2_before.first()).clip(boundary)\n",
    "    name=leak_id+'_before'\n",
    "    path,files=download_image(\n",
    "        image, \n",
    "        scale=resolution_min, \n",
    "        crs=crs_grid, \n",
    "        name=name,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "    # also save metadata so we can filter by date\n",
    "    with open(path.joinpath('metadata.json'), 'w') as fo:\n",
    "        metadata = dict(\n",
    "            image=image.getInfo(),\n",
    "            scale=resolution_min,\n",
    "            crs=crs_grid,\n",
    "            name=name,\n",
    "            distance=distance,\n",
    "            leak=json.loads(leak.to_json())\n",
    "        )\n",
    "        json.dump(metadata, fo)\n",
    "\n",
    "    image = ee.Image(sentinel2_after.first()).clip(boundary)\n",
    "    name=leak_id+'_after'\n",
    "    path,files=download_image(\n",
    "        image, \n",
    "        scale=resolution_min, \n",
    "        crs=crs_grid, \n",
    "        name=name,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "    with open(path.joinpath('metadata.json'), 'w') as fo:\n",
    "        metadata = dict(\n",
    "            image=image.getInfo(),\n",
    "            scale=resolution_min,\n",
    "            crs=crs_grid,\n",
    "            name=name,\n",
    "            distance=distance,\n",
    "            leak=json.loads(leak.to_json())\n",
    "        )\n",
    "        json.dump(metadata, fo)\n",
    "        \n",
    "# could take 27 hours\n",
    "leak_to_scrape = set(leaks.leak_id).difference(set(['ATX_'+i for i in cached_ids]))\n",
    "# leak_to_scrape = set(leaks.id).difference(set(cached_ids))\n",
    "for i in tqdm(leak_to_scrape):\n",
    "    try:\n",
    "        get_image_for_leak(i)\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(i,e) # \"HTTP Error 429: unknown\"\n",
    "        traceback.print_stack()\n",
    "        if e.code == 429:\n",
    "            print('sleep for 13s')\n",
    "            time.sleep(13);\n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(i,e) # \"Earth Engine memory capacity exceeded.\"\n",
    "        traceback.print_stack()\n",
    "        ee.Initialize()\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(i,e) # \"File is not a zip file\"\n",
    "        traceback.print_stack()\n",
    "    except Exception as e:\n",
    "        print(i,e)\n",
    "        # e.g. \"An internal server error has occurred (216bc442fe171620592bc53fb578bceb).\"\n",
    "        traceback.print_stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing tiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:39:15.511039Z",
     "start_time": "2017-03-21T10:39:15.494370+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:44:12.872335Z",
     "start_time": "2017-03-21T10:44:12.865381+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T02:40:52.813228Z",
     "start_time": "2017-03-21T10:40:52.803165+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T08:58:43.328547Z",
     "start_time": "2017-03-21T16:14:14.053464+08:00"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25469e29d9cc40d4aa1aedfa3d676f9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15211, 0)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This loads it as X and y for machine learning, and also time and metadata so we can filter\n",
    "import shapely\n",
    "X = []\n",
    "y = []\n",
    "t = []\n",
    "m = []\n",
    "discarded=[]\n",
    "cdirs = [cdir for cdir in cache_dir.listdir() if ('_after_' in cdir) or ('_before_' in cdir)]\n",
    "for path in tqdm(cdirs):\n",
    "    if not path.isdir(): continue\n",
    "    files = [file.relpath(path) for file in path.listdir() if file.endswith('.tif')]\n",
    "    if files:\n",
    "        # check metadata\n",
    "        try:\n",
    "            metadata = json.load(open(path.joinpath('metadata.json')))\n",
    "        except (FileNotFoundError, ValueError) as e:\n",
    "            path.move(path.dirname().dirname().joinpath('.deleteme-'+str(uuid.uuid4())))\n",
    "            if '_after_' in path: # also delete the before path                \n",
    "                path_after = Path(path.replace('_after_','_before_'))\n",
    "                if path_after.isdir():\n",
    "                    path_after.move(path.dirname().dirname().joinpath('.deleteme-'+str(uuid.uuid4())))\n",
    "            logger.error('Invalid metadata.json, deleted folder %s, please rerun scraping cell to rescrape this image', path)\n",
    "            continue\n",
    "        \n",
    "        # e.g. lets filter it so \"before\" image are only 1 day before\n",
    "        if '_before_' in path.basename():\n",
    "            yy = True\n",
    "        else:\n",
    "            yy = False\n",
    "        \n",
    "        # work out time gap too\n",
    "        t1 = arrow.get(metadata['image']['properties']['system:time_end']/1000)\n",
    "        t0 = arrow.get(metadata['leak']['features'][0]['properties']['REPO_Date'])\n",
    "        td=t1-t0\n",
    "        tt = td.total_seconds()\n",
    "        \n",
    "        # load data\n",
    "        data = tifs2np(path,files,bands=bands)\n",
    "             \n",
    "        # check we don't have empty bands 1-13\n",
    "        empty_bands = np.array([d.sum() for d in data])==0\n",
    "        \n",
    "        # lets check we didn't get the edge of an image\n",
    "        bbox = np.array(metadata['image']['properties']['system:footprint']['coordinates'][0])\n",
    "        loc = metadata['leak']['features'][0]['geometry']['coordinates']\n",
    "        minx=bbox[:,0].min()\n",
    "        maxx=bbox[:,0].max()\n",
    "        miny=bbox[:,1].min()\n",
    "        maxy=bbox[:,1].max()\n",
    "        bbox_shp = shapely.geometry.box(\n",
    "            minx=minx,\n",
    "            maxx=maxx,\n",
    "            miny=miny,\n",
    "            maxy=maxy\n",
    "        )\n",
    "        loc_shp = shapely.geometry.Point(loc[0],loc[1])\n",
    "        shapely.geometry.GeometryCollection([bbox_shp, loc_shp])\n",
    "        try:\n",
    "            assert loc_shp.intersects(bbox_shp), 'leak location should be inside image'\n",
    "            assert bbox_shp.centroid.almost_equals(loc_shp, decimal=5), 'leak should be near center of image'\n",
    "            assert (np.array([d.shape for d in data])==pixel_length).all(), 'image area should be the right amount of pixels'\n",
    "            assert (maxx-minx)/(maxy-miny)<1.3, 'should be roughly square'\n",
    "            assert (maxx-minx)/(maxy-miny)>0.7, 'should be roughly square'\n",
    "            assert not empty_bands.all(), 'should not have all bands empty'\n",
    "        except Exception as exc:\n",
    "            print(path, exc)\n",
    "#             raise(exc)\n",
    "            discarded.append(path)\n",
    "        else:\n",
    "            X.append(data)\n",
    "            y.append(yy)\n",
    "            t.append(tt)\n",
    "            m.append(metadata)\n",
    "        \n",
    "\n",
    "len(X), len(discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-18T04:31:06.685512Z",
     "start_time": "2017-03-18T12:31:06.679839+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T09:05:16.351164Z",
     "start_time": "2017-03-21T17:05:16.338206+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle\n",
    "from sklearn.utils import shuffle\n",
    "X,y,m= shuffle(X,y,m,random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T09:05:17.333041Z",
     "start_time": "2017-03-21T17:05:17.121365+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of each band [('B1', 0), ('B2', 0), ('B3', 0), ('B4', 0), ('B5', 0), ('B6', 0), ('B7', 0), ('B8', 0), ('B9', 0), ('B10', 0), ('B11', 0), ('BQA', 0)]\n",
      "mean amount of bands 0.0\n"
     ]
    }
   ],
   "source": [
    "# which empty bands do we have?\n",
    "a=np.array([x.sum(-1).sum(-1)==0 for x in X])\n",
    "print('amount of each band',list(zip(bands_l8,a.sum(0))))\n",
    "print('mean amount of bands',a.sum(1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T23:33:11.187419Z",
     "start_time": "2017-03-15T07:33:11.182833+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T09:05:51.659879Z",
     "start_time": "2017-03-21T17:05:20.001215+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# save using hdf5 (so keras can easily load it) and json \n",
    "import h5py\n",
    "h5file = output_dir.joinpath('data.h5')\n",
    "with h5py.File(h5file, 'w') as h5f:\n",
    "    h5f.create_dataset('X', data=X)\n",
    "    h5f.create_dataset('y', data=y)\n",
    "\n",
    "json.dump(m,open(output_dir.joinpath('data_metadata.json'),'w'))\n",
    "\n",
    "with open(output_dir.joinpath('readme.md'),'w') as fo:\n",
    "    fo. write(\"\"\"\n",
    "Files:\n",
    "- cache- cached tiff files\n",
    "- script_metadata.json - information on scraping script\n",
    "- data.h5 contains X, y, and t.\n",
    "    - X: tiff files for each band loaded into an array of shape (Leak, Bands, width, length)\n",
    "    - y: True for before the leak, False for after\n",
    "- data_metadata: array of metadata for each leak in X. Each contain info on leak, image, and image search\n",
    "    \n",
    "Loading: \n",
    "```py\n",
    "# load\n",
    "metadatas = json.load(open('data_metadata.json'))\n",
    "with h5py.File('data.h5','r') as h5f:\n",
    "    X2 = h5f['X'][:]\n",
    "    y2 = h5f['y'][:]\n",
    "y\n",
    "```\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-21T08:59:20.773234Z",
     "start_time": "2017-03-21T16:59:15.215555+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15211, 12, 25, 25),\n",
       " array([False,  True, False, ...,  True,  True, False], dtype=bool),\n",
       " dict_keys(['name', 'leak', 'image', 'distance', 'scale', 'crs']))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test load\n",
    "metadatas = json.load(open(output_dir.joinpath('data_metadata.json')))\n",
    "with h5py.File(output_dir.joinpath('data.h5'),'r') as h5f:\n",
    "    X2 = h5f['X'][:]\n",
    "    y2 = h5f['y'][:]\n",
    "X2.shape, y2, metadatas[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T05:14:58.720471Z",
     "start_time": "2017-03-14T13:14:58.704557+08:00"
    },
    "collapsed": true
   },
   "source": [
    "# test deleteme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T23:27:58.803590Z",
     "start_time": "2017-03-15T07:27:58.060356+08:00"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']=\"\" # to disable gpu, so I can do large predictions in memory\n",
    "\n",
    "helper_dir = str(Path('.').abspath())\n",
    "if helper_dir not in os.sys.path:\n",
    "    os.sys.path.append(helper_dir)\n",
    "\n",
    "from leak_helpers.earth_engine import display_ee, get_boundary, tifs2np, bands_s2, download_image, bands_s2\n",
    "from leak_helpers.geometry import diffxy, resample_polygon\n",
    "from leak_helpers.modelling import ImageDataGenerator, dice_coef_loss\n",
    "from leak_helpers.visualization import imshow_bands\n",
    "from leak_helpers.analysis import parse_classification_report, find_best_dummy_classification, calculate_result_class\n",
    "from leak_helpers.modelling.filters import is_not_cloudy, is_not_center_cloudy, is_image_within, is_leak, filter_split_data, is_not_dup, hash_rows, normalise_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T23:27:58.811005Z",
     "start_time": "2017-03-15T07:27:58.805233+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-371640.0380"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md=m[2]\n",
    "t_image = arrow.get(md['image']['properties']['system:time_end'] / 1000)\n",
    "t_leak = arrow.get(md['leak']['features'][0]['properties']['REPO_Date'])\n",
    "seconds_before_leak = (t_leak - t_image).total_seconds()\n",
    "seconds_before_leak#<60*60*24*4\n",
    "# [is_image_within(mm, 60*60*24*4) for mm in m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T05:20:21.838726Z",
     "start_time": "2017-03-14T13:20:21.821046+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T23:27:58.826617Z",
     "start_time": "2017-03-15T07:27:58.812797+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# has_three_bands = np.array([x.sum(-1).sum(-1)==0 for x in X]).sum(1)>2\n",
    "\n",
    "\n",
    "# X = X[keep]\n",
    "# y = y[keep]\n",
    "# m = [m[i] for i in range(len(m)) if keep[i]]\n",
    "# print('kept',keep.sum(),'of',len(keep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T23:27:59.570140Z",
     "start_time": "2017-03-15T07:27:59.512918+08:00"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, metadata_train, metadata_test = train_test_split(\n",
    "        X, y, m)\n",
    "\n",
    "X_train2 = X_train.reshape((len(X_train),-1))\n",
    "X_test2 = X_test.reshape((len(X_test),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T23:28:06.360531Z",
     "start_time": "2017-03-15T07:28:02.080742+08:00"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isisilon/.virtualenvs/py3syspck/lib/python3.4/site-packages/sklearn/metrics/classification.py:516: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(var_yt * var_yp)\n",
      "/home/isisilon/.virtualenvs/py3syspck/lib/python3.4/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "target_names = ['noleak','leak']\n",
    "df_dummies, best_dummy = find_best_dummy_classification(X,y,n=50, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-14T23:28:52.188355Z",
     "start_time": "2017-03-15T07:28:06.362245+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     noleak       0.57      0.55      0.56       618\n",
      "       leak       0.59      0.61      0.60       663\n",
      "\n",
      "avg / total       0.58      0.58      0.58      1281\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5792, 0.1565)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "thresh=0.5\n",
    "clf = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "#     criterion='entropy',\n",
    "#     max_depth=None, \n",
    "    min_samples_split=6, \n",
    "    min_samples_leaf=6,\n",
    "#     max_features='auto', \n",
    "#     bootstrap=True,\n",
    "#         random_state=0,\n",
    "#     n_jobs=4, \n",
    ")\n",
    "\n",
    "clf.fit(X_train2, y_train) \n",
    "\n",
    "y_pred = clf.predict(X_test2)\n",
    "score = clf.score(X_test2, y_test)\n",
    "\n",
    "matthews_corrcoef = sklearn.metrics.matthews_corrcoef(y_test>thresh, y_pred>thresh)\n",
    "print(sklearn.metrics.classification_report(y_test > thresh, y_pred > thresh, target_names=target_names))\n",
    "score,matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (with sys packages)",
   "language": "python",
   "name": "py3syspck"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  },
  "toc": {
   "nav_menu": {
    "height": "96px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
